# -*- coding: utf-8 -*-
"""FeatureSelection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XNmP7C4nN6ovv8nDOPTa9HTsGUz28ErZ

**Importing Libraries**
"""

import pandas as pd
import cv2
import tensorflow
from sklearn.model_selection import train_test_split
from tensorflow import keras
from sklearn.feature_selection import SelectPercentile
from sklearn.feature_selection import chi2 , f_classif
#Import SVM Classifier model
from sklearn import svm
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
#Import knearest neighbors Classifier model
from sklearn.neighbors import KNeighborsClassifier
#Import MLPClassifier Classifier model
from sklearn.neural_network import MLPClassifier
#Import classification_report from scikit-learn metrics module for NN Report  
from sklearn.metrics import classification_report

"""**Load Data**"""

data = pd.read_csv("data.csv")
#preprossing the data 
new_dataset=data.drop(['Unnamed: 32', 'id'],axis=1)
#Encoding diagnosis classes 
new_dataset['diagnosis']=new_dataset['diagnosis'].replace('M', 1)
new_dataset['diagnosis']=new_dataset['diagnosis'].replace('B', 0)
#split the data to X and Y ( X -> Features , Y -> class ) 
X = new_dataset.iloc[:, 1:]
y = new_dataset.iloc[:, 0:1]

# print(X.shape)
# print(y.shape)
# print(y)


#store features name
colNames = list(X.columns)

#Select features according to a percentile of the highest scores
FeatureSelection = SelectPercentile(score_func = chi2, percentile=60) # score_func can = f_classif
Features = FeatureSelection.fit_transform(X, y)
Features

#showing X Dimension
# print('X Shape is ' , Features.shape)
# print('Selected Features are : ' , FeatureSelection.get_support())

#Feature Selected
features_name=list(FeatureSelection.get_support())

#Extracting The features name 
selected_feature_name=[]

for i in range(len(features_name)):
    if features_name[i]:
        selected_feature_name.append(colNames[i])

#print Selected Feature Names 
selected_feature_name

"""**Spliting the data With the new selected features**



"""

#extracting only the selected features data from whole data
X= X[selected_feature_name]
#Splitng
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# print(X_train.shape)
# print(X_test.shape)
# print(y_train.shape)
# print(y_test.shape)

"""**Calling Models**"""

print("*************SVM*************")

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train.values.ravel())

#Predict the response for test dataset
y_pred = clf.predict(X_test)


# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

print("*************KNN*************")

#Create KNN Classifier
knn = KNeighborsClassifier(n_neighbors=7)

#Train the model using the training sets
knn.fit(X_train, y_train.values.ravel())

#Predict the response for test dataset
y_pred = knn.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?

print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

print("*************MLPNN*************")
mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)
mlp.fit(X_train, y_train.values.ravel())
y_pred = mlp.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))
# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))
#antor way to print repoort for accuarcy and percision and recall
print(classification_report(y_test,y_pred))